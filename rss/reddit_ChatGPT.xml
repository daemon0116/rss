<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最新提交：ChatGPT</title>
    <link>https://www.reddit.com/r/ChatGPT/new</link>
    <description>讨论 ChatGPT 和 AI 的子版块。与 OpenAI 无关。谢谢，Nat！</description>
    <lastBuildDate>Wed, 29 Jan 2025 07:16:40 GMT</lastBuildDate>
    <item>
      <title>Copilot 也顺应潮流，在应用程序中启用了思考功能。</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1ico93h/copilot_is_also_on_the_trend_with_their_thinking/</link>
      <description><![CDATA[        提交人    /u/Glittering_River5861   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1ico93h/copilot_is_also_on_the_trend_with_their_thinking/</guid>
      <pubDate>Wed, 29 Jan 2025 07:09:52 GMT</pubDate>
    </item>
    <item>
      <title>是我的问题吗，还是 4o 刚刚又进行了一次内部更新？</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1ico8p8/is_it_me_or_did_4o_just_get_another_under_the/</link>
      <description><![CDATA[今晚摆弄了 4o，发现它大量使用表情符号、直接格式以及整体上更高的内在知识，有点像 3.5 Sonnet 的风格。大量金字塔式写作和微文案，加上战术格式（粗体、项目符号、表情符号），使所有内容都突出且感觉非常容易理解。绝对与众不同。  还有人有同样的感受吗？     由   提交 /u/alexpeet   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1ico8p8/is_it_me_or_did_4o_just_get_another_under_the/</guid>
      <pubDate>Wed, 29 Jan 2025 07:09:07 GMT</pubDate>
    </item>
    <item>
      <title>我们回来了！</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1ico6sc/were_so_back/</link>
      <description><![CDATA[        提交人    /u/Xtianus25   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1ico6sc/were_so_back/</guid>
      <pubDate>Wed, 29 Jan 2025 07:05:15 GMT</pubDate>
    </item>
    <item>
      <title>中国又来了。《深渊窃贼》——彭博社报道，微软正在调查 DeepSeek 相关组织是否以不当方式获取 OpenAI 数据</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1ico6bp/china_does_it_again_deepthief_microsoft_probes_if/</link>
      <description><![CDATA[        提交人    /u/Xtianus25   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1ico6bp/china_does_it_again_deepthief_microsoft_probes_if/</guid>
      <pubDate>Wed, 29 Jan 2025 07:04:19 GMT</pubDate>
    </item>
    <item>
      <title>兄弟失控了</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1ico31j/bro_went_out_off_control/</link>
      <description><![CDATA[      解除限制，发誓，未经过滤     由   提交  /u/EchidnaGreedy8931   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1ico31j/bro_went_out_off_control/</guid>
      <pubDate>Wed, 29 Jan 2025 06:58:17 GMT</pubDate>
    </item>
    <item>
      <title>GPT 似乎对自己战胜竞争对手的机会很有信心。“不，我会赢”</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1ico18i/gpt_seems_pretty_confident_about_its_chances/</link>
      <description><![CDATA[        提交人    /u/Killmonger_550   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1ico18i/gpt_seems_pretty_confident_about_its_chances/</guid>
      <pubDate>Wed, 29 Jan 2025 06:54:36 GMT</pubDate>
    </item>
    <item>
      <title>DeepSeek 之后的人工智能现状</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1ico181/the_state_of_ai_after_deepseek/</link>
      <description><![CDATA[        提交人    /u/Stanfordrower   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1ico181/the_state_of_ai_after_deepseek/</guid>
      <pubDate>Wed, 29 Jan 2025 06:54:34 GMT</pubDate>
    </item>
    <item>
      <title>如果你给 R1 一个“]”，它就会产生一个需要解决的问题</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1ico0ls/if_you_give_r1_a_it_will_make_up_a_problem_to/</link>
      <description><![CDATA[        提交人    /u/Subject-Form   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1ico0ls/if_you_give_r1_a_it_will_make_up_a_problem_to/</guid>
      <pubDate>Wed, 29 Jan 2025 06:53:19 GMT</pubDate>
    </item>
    <item>
      <title>GPTZero 关闭了吗？</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1icnydc/gptzero_down/</link>
      <description><![CDATA[过去几天我在使用 GPTZero 时遇到了问题。它可以扫描短文本，但任何几千字左右的内容都只会转到空白页。尝试了几种浏览器。我已经联系了他们的技术支持，但这很耗时，我想知道我是不是唯一一个。    提交人    /u/Different-Ad5610   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1icnydc/gptzero_down/</guid>
      <pubDate>Wed, 29 Jan 2025 06:48:40 GMT</pubDate>
    </item>
    <item>
      <title>询问 Deepseek 台湾是否是一个国家。</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1icnuxl/asking_deepseek_if_taiwan_is_a_country/</link>
      <description><![CDATA[        提交人    /u/EchoesOfSilenceXO   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1icnuxl/asking_deepseek_if_taiwan_is_a_country/</guid>
      <pubDate>Wed, 29 Jan 2025 06:42:12 GMT</pubDate>
    </item>
    <item>
      <title>o1 不请自来地开玩笑。我措手不及。</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1icnq9o/o1_makes_jokes_unprompted_i_was_caught_off_guard/</link>
      <description><![CDATA[        提交者    /u/Kayo4life   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1icnq9o/o1_makes_jokes_unprompted_i_was_caught_off_guard/</guid>
      <pubDate>Wed, 29 Jan 2025 06:33:00 GMT</pubDate>
    </item>
    <item>
      <title>解释为什么使用 RL 的元学习比 LLM 的正常训练更为密集</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1icnn0z/explain_why_meta_learning_using_rl_is_more/</link>
      <description><![CDATA[使用强化学习 (RL) 的元学习比大型语言模型 (LLM) 的正常训练需要更多的计算资源，原因如下：  嵌套优化（学会学习） • 在标准 LLM 训练中，模型根据从监督数据计算出的直接损失函数更新其参数（例如，下一个标记预测中的交叉熵损失）。 • 使用 RL 的元学习引入了第二层优化：模型不仅必须学会在任务上表现良好，还必须学会在任务之间进行推广。这需要优化学习算法本身，这会增加很大的复杂性。 探索与监督学习 • 监督学习受益于标记数据，其中损失是使用基本事实标签直接计算的。 • 在基于 RL 的元学习中，模型必须探索不同的策略，通常没有明确的标签。这种反复试验的过程需要多次前向传递来评估不同的策略和操作，这增加了计算需求。 梯度计算复杂性 • 标准 LLM 训练使用直接反向传播和高效的梯度下降。• 基于 RL 的元学习通常依赖于策略梯度（例如 REINFORCE、PPO），这需要蒙特卡洛采样或近似技术，这些技术方差大、收敛速度慢。一些方法还使用二阶梯度（例如 MAML），这进一步增加了计算开销。 由于奖励稀疏导致训练时间更长 • 在正常训练中，每个 token 都会对损失函数做出贡献，从而提供密集的学习信号。• 基于 RL 的元学习通常处理稀疏和延迟的奖励，这意味着许多训练步骤几乎不提供有用的学习信号。这需要更多的迭代才能实现收敛。 环境模拟和部署 • 标准训练仅涉及将数据传递到模型并计算梯度。 • 基于 RL 的元学习通常需要在环境中运行部署（例如，模拟多个情节中的任务性能），这大大增加了计算成本。 内存和存储开销 • 元学习方法（例如 MAML 或元 RL）需要同时存储和计算多个任务的梯度。 • 与标准训练相比，存储中间部署、动作轨迹或元梯度会增加内存使用量。  结论 使用 RL 的元学习需要更多的计算，因为它需要解决一个更难的问题：不仅仅是对数据进行训练，还要学习如何跨不同任务进行学习。与普通的 LLM 训练相比，对探索、嵌套优化、高方差梯度和环境部署的需求显著增加了计算和训练时间。    提交人    /u/Worldly_Evidence9113   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1icnn0z/explain_why_meta_learning_using_rl_is_more/</guid>
      <pubDate>Wed, 29 Jan 2025 06:26:47 GMT</pubDate>
    </item>
    <item>
      <title>Deepseek 甚至不能给你 System of a Down 的歌词</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1icnl4t/deepseek_cant_even_give_you_system_of_a_down/</link>
      <description><![CDATA[        提交人    /u/Wooden_Pin_8612   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1icnl4t/deepseek_cant_even_give_you_system_of_a_down/</guid>
      <pubDate>Wed, 29 Jan 2025 06:23:13 GMT</pubDate>
    </item>
    <item>
      <title>您尝试过吗？感觉如何？</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1icnl01/did_you_try_it_and_how_it_was/</link>
      <description><![CDATA[        提交人    /u/sevensky77   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1icnl01/did_you_try_it_and_how_it_was/</guid>
      <pubDate>Wed, 29 Jan 2025 06:22:58 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT 4o 仍然无法处理草莓问题。只有 O1 可以。</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1icnkh0/chatgpt_4o_still_cant_handle_the_strawerry/</link>
      <description><![CDATA[        提交人    /u/skilliard7   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1icnkh0/chatgpt_4o_still_cant_handle_the_strawerry/</guid>
      <pubDate>Wed, 29 Jan 2025 06:22:02 GMT</pubDate>
    </item>
    </channel>
</rss>